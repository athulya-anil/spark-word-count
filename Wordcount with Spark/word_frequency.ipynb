{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-10T21:02:17.628624Z",
     "start_time": "2024-10-10T21:02:17.512938Z"
    }
   },
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, explode, lower, count, desc"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T21:02:19.413429Z",
     "start_time": "2024-10-10T21:02:17.666564Z"
    }
   },
   "cell_type": "code",
   "source": "spark = SparkSession.builder.appName(\"jehfuh\").getOrCreate()",
   "id": "a6ba3e0dc476aa0e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/10 17:02:18 WARN Utils: Your hostname, Nikhils-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 10.0.0.206 instead (on interface en0)\n",
      "24/10/10 17:02:18 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/10 17:02:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T21:02:21.225661Z",
     "start_time": "2024-10-10T21:02:19.456020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hamlet_df = spark.read.text(\"hamlet.txt\")\n",
    "hamlet_df.show()"
   ],
   "id": "2c0eedce13a689c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|             HAMLET,|\n",
      "|  PRINCE OF DENMARK.|\n",
      "|              ACT I.|\n",
      "|Scene I.—ELSINORE...|\n",
      "|Francisco on his ...|\n",
      "|                    |\n",
      "|   Ber. Who's there?|\n",
      "|                    |\n",
      "|Fran. (R.) Nay, a...|\n",
      "|                    |\n",
      "|Ber. Long live th...|\n",
      "|                    |\n",
      "|               Fran.|\n",
      "|           Bernardo?|\n",
      "|                    |\n",
      "|                Ber.|\n",
      "|                 He.|\n",
      "|                    |\n",
      "|Fran. You come mo...|\n",
      "|                    |\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T21:02:21.348904Z",
     "start_time": "2024-10-10T21:02:21.244791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the lines into words\n",
    "from pyspark.sql.functions import lower\n",
    "df_split = hamlet_df.select(split(lower(hamlet_df.value), ' ').alias(\"word\"))\n",
    "df_split.show()"
   ],
   "id": "a5d909246a7f56f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                word|\n",
      "+--------------------+\n",
      "|           [hamlet,]|\n",
      "|[prince, of, denm...|\n",
      "|           [act, i.]|\n",
      "|[scene, i.—elsino...|\n",
      "|[francisco, on, h...|\n",
      "|                  []|\n",
      "|[ber., who's, the...|\n",
      "|                  []|\n",
      "|[fran., (r.), nay...|\n",
      "|                  []|\n",
      "|[ber., long, live...|\n",
      "|                  []|\n",
      "|             [fran.]|\n",
      "|         [bernardo?]|\n",
      "|                  []|\n",
      "|              [ber.]|\n",
      "|               [he.]|\n",
      "|                  []|\n",
      "|[fran., you, come...|\n",
      "|                  []|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T21:02:21.501906Z",
     "start_time": "2024-10-10T21:02:21.368353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_lower = df_split.select(explode(df_split.word).alias(\"word\"))\n",
    "df_lower.show()"
   ],
   "id": "42d71ff489eb4729",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|        word|\n",
      "+------------+\n",
      "|     hamlet,|\n",
      "|      prince|\n",
      "|          of|\n",
      "|    denmark.|\n",
      "|         act|\n",
      "|          i.|\n",
      "|       scene|\n",
      "|i.—elsinore.|\n",
      "|           a|\n",
      "|    platform|\n",
      "|      before|\n",
      "|         the|\n",
      "|     castle.|\n",
      "|      night.|\n",
      "|   francisco|\n",
      "|          on|\n",
      "|         his|\n",
      "|       post.|\n",
      "|       enter|\n",
      "|          to|\n",
      "+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T21:02:21.627453Z",
     "start_time": "2024-10-10T21:02:21.526107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "df_lower_split = hamlet_df.select(explode(split(lower(hamlet_df.value), ' ')).alias('word'))\n",
    "# df_lower_split.show()\n",
    "df_cleaned = df_lower_split.withColumn('word', regexp_replace(df_lower_split.word, '[^a-zA-Z0-9\\\\s]', '').alias('words'))\n",
    "df_cleaned.show()"
   ],
   "id": "a2cb36b5d216b984",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     word|\n",
      "+---------+\n",
      "|   hamlet|\n",
      "|   prince|\n",
      "|       of|\n",
      "|  denmark|\n",
      "|      act|\n",
      "|        i|\n",
      "|    scene|\n",
      "|ielsinore|\n",
      "|        a|\n",
      "| platform|\n",
      "|   before|\n",
      "|      the|\n",
      "|   castle|\n",
      "|    night|\n",
      "|francisco|\n",
      "|       on|\n",
      "|      his|\n",
      "|     post|\n",
      "|    enter|\n",
      "|       to|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T21:02:21.743839Z",
     "start_time": "2024-10-10T21:02:21.637137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import importlib\n",
    "import assignment3.data_cleaner as dc\n",
    "\n",
    "importlib.reload(dc)\n",
    "\n",
    "hamlet_cleaned_df = dc.clean_dataset(hamlet_df)\n",
    "hamlet_cleaned_df.show()"
   ],
   "id": "5c6078b123d5560a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     word|\n",
      "+---------+\n",
      "|   hamlet|\n",
      "|   prince|\n",
      "|       of|\n",
      "|  denmark|\n",
      "|      act|\n",
      "|        i|\n",
      "|    scene|\n",
      "|ielsinore|\n",
      "|        a|\n",
      "| platform|\n",
      "|   before|\n",
      "|      the|\n",
      "|   castle|\n",
      "|    night|\n",
      "|francisco|\n",
      "|       on|\n",
      "|      his|\n",
      "|     post|\n",
      "|    enter|\n",
      "|       to|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T21:02:21.772857Z",
     "start_time": "2024-10-10T21:02:21.759511Z"
    }
   },
   "cell_type": "code",
   "source": "word_count = hamlet_cleaned_df.groupBy('word').count()",
   "id": "449238e6aafe651",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T21:02:22.324944Z",
     "start_time": "2024-10-10T21:02:21.804124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sort the words by frequency in descending order and get the top 20\n",
    "top_words = word_count.orderBy(desc('count')).limit(20)\n",
    "\n",
    "# Show the top 20 most frequent words with their counts\n",
    "top_words.show(truncate=False)"
   ],
   "id": "51dc887579c72251",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "|the |1186 |\n",
      "|and |753  |\n",
      "|to  |740  |\n",
      "|of  |692  |\n",
      "|a   |534  |\n",
      "|you |447  |\n",
      "|in  |423  |\n",
      "|i   |407  |\n",
      "|my  |393  |\n",
      "|it  |338  |\n",
      "|is  |337  |\n",
      "|that|304  |\n",
      "|not |263  |\n",
      "|ham |261  |\n",
      "|his |254  |\n",
      "|this|239  |\n",
      "|with|229  |\n",
      "|your|228  |\n",
      "|for |213  |\n",
      "|as  |207  |\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T21:02:22.848616Z",
     "start_time": "2024-10-10T21:02:22.340899Z"
    }
   },
   "cell_type": "code",
   "source": "spark.stop()",
   "id": "49ae56dccdd93288",
   "outputs": [],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
